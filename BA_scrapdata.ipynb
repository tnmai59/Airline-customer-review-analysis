{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse to web\n",
    "def web_parser(link, headers = {'User-Agent': 'Mozilla/5.0'}):\n",
    "    req = Request(\n",
    "    url= link, \n",
    "    headers={'User-Agent': 'Mozilla/5.0'}\n",
    "    )\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(soup):\n",
    "    links = soup.find('article', class_='comp comp_reviews-pagination querylist-pagination position-').find('ul').find_all('a')\n",
    "    new_url = 'https://www.airlinequality.com' + links[-1].get('href')\n",
    "    return new_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def craw_data_review(soup):\n",
    "    dataset = []\n",
    "    count = 1\n",
    "    while True:\n",
    "        review_date = soup.find_all('meta', itemprop = 'datePublished')\n",
    "        review_title = soup.find_all('h2', class_='text_header')\n",
    "        review_text = soup.find_all('div', class_= 'text_content', itemprop='reviewBody')\n",
    "        for i in range(len(review_text)):\n",
    "            temp_rv_title = review_title[i].get_text(strip=True)\n",
    "            temp_rv_date = review_date[i].get('content')\n",
    "            if review_text[i].get_text(strip = True).find('| ') == -1:\n",
    "                temp_review = review_text[i].get_text(strip = True)\n",
    "                dataset.append({'Review date': temp_rv_date, 'Review title': temp_rv_title, 'Review': temp_review})\n",
    "            else:\n",
    "                temp_review = review_text[i].get_text(strip=True).split('| ')[1:]\n",
    "                dataset.append({'Review date': temp_rv_date, 'Review title': temp_rv_title, 'Review': ' '.join(temp_review).strip()})\n",
    "            \n",
    "        link = get_link(soup)\n",
    "        new_soup = web_parser(link)\n",
    "        if new_soup == soup:\n",
    "            print(\"Last page\")\n",
    "            break\n",
    "        else:\n",
    "            soup = new_soup\n",
    "            print(f\"Finish page {count}\")\n",
    "        count += 1\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(\n",
    "    url= 'https://www.airlinequality.com/airline-reviews/british-airways', \n",
    "    headers={'User-Agent': 'Mozilla/5.0'}\n",
    ")\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = craw_data_review(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lst):\n",
    "   res_dict = {}\n",
    "   for i in range(0, len(lst), 2):\n",
    "       res_dict[lst[i]] = lst[i + 1]\n",
    "   return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_data_stat(soup):\n",
    "    review_stats = []\n",
    "    count = 1\n",
    "    while True:\n",
    "        stats = soup.find_all('div', class_='review-stats')\n",
    "        rv_date = soup.find_all('meta', itemprop = 'datePublished')\n",
    "        for i in range(len(stats)):\n",
    "            table = stats[i].find_all('td')\n",
    "            temp_rv_date = rv_date[i].get('content')\n",
    "            temp = []\n",
    "            for j in range(0, len(table)):\n",
    "                if table[j].get('class') == ['review-rating-stars', 'stars']:\n",
    "                    if len(table[j].find_all('span', class_ =\"star fill\")) != 0:\n",
    "                        value = table[j].find_all('span', class_ =\"star fill\")[-1].get_text()\n",
    "                else:\n",
    "                    value = table[j].get_text()\n",
    "                temp.append(value)\n",
    "            temp.append('Review date')\n",
    "            temp.append(temp_rv_date)\n",
    "            review_stats.append(convert(temp))\n",
    "        link = get_link(soup)\n",
    "        new_soup = web_parser(link)\n",
    "        if new_soup == soup:\n",
    "            print(\"Last page\")\n",
    "            break\n",
    "        else:\n",
    "            soup = new_soup\n",
    "            print(f'Finish page {count}')\n",
    "        count += 1\n",
    "    return review_stats\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_stats = crawl_data_stat(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(review_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('C:/Users/HP/OneDrive - National Economics University/Data Prep/Class code/review_stats_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_stata('C:/Users/HP/OneDrive - National Economics University/Data Prep/Class code/review_stats_data.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "dataframe1 = pd.DataFrame(mydata)\n",
    "dataframe1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1.to_csv('C:/Users/HP/OneDrive - National Economics University/Data Prep/Class code/review_text_data.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
